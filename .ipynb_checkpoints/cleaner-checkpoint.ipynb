{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93f11dbc-aa07-49d7-b90e-781de23dbab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a743dd92-1f1d-4131-8610-4acdbb38f32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Item</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price Per Unit</th>\n",
       "      <th>Total Spent</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Location</th>\n",
       "      <th>Transaction Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXN_1961373</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-09-08 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TXN_4977031</td>\n",
       "      <td>Cake</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>Cash</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-05-16 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TXN_4271903</td>\n",
       "      <td>Cookie</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-07-19 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TXN_7034554</td>\n",
       "      <td>Salad</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>2023-04-27 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TXN_3160411</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-06-11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>TXN_7672686</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>2023-08-30 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>TXN_9659401</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-06-02 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>TXN_5255387</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-03-02 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>TXN_7695629</td>\n",
       "      <td>Cookie</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-02 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>TXN_6170729</td>\n",
       "      <td>Sandwich</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>Cash</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-11-07 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Transaction ID      Item Quantity Price Per Unit Total Spent  \\\n",
       "0       TXN_1961373    Coffee        2              2           4   \n",
       "1       TXN_4977031      Cake        4              3          12   \n",
       "2       TXN_4271903    Cookie        4              1       ERROR   \n",
       "3       TXN_7034554     Salad        2              5          10   \n",
       "4       TXN_3160411    Coffee        2              2           4   \n",
       "...             ...       ...      ...            ...         ...   \n",
       "9995    TXN_7672686    Coffee        2              2           4   \n",
       "9996    TXN_9659401       NaN        3            NaN           3   \n",
       "9997    TXN_5255387    Coffee        4              2           8   \n",
       "9998    TXN_7695629    Cookie        3            NaN           3   \n",
       "9999    TXN_6170729  Sandwich        3              4          12   \n",
       "\n",
       "      Payment Method  Location     Transaction Date  \n",
       "0        Credit Card  Takeaway  2023-09-08 00:00:00  \n",
       "1               Cash  In-store  2023-05-16 00:00:00  \n",
       "2        Credit Card  In-store  2023-07-19 00:00:00  \n",
       "3            UNKNOWN   UNKNOWN  2023-04-27 00:00:00  \n",
       "4     Digital Wallet  In-store  2023-06-11 00:00:00  \n",
       "...              ...       ...                  ...  \n",
       "9995             NaN   UNKNOWN  2023-08-30 00:00:00  \n",
       "9996  Digital Wallet       NaN  2023-06-02 00:00:00  \n",
       "9997  Digital Wallet       NaN  2023-03-02 00:00:00  \n",
       "9998  Digital Wallet       NaN  2023-12-02 00:00:00  \n",
       "9999            Cash  In-store  2023-11-07 00:00:00  \n",
       "\n",
       "[10000 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "file_name = 'sales.xlsx'\n",
    "df = pd.read_excel(\"data/\"+file_name)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b43852f9-4a6d-4950-bf77-bc083e3620ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "print(len(\"                                                                               \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96b0be31-2059-4b73-a9a7-a2dd129bedc9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Validation Report: Transaction ID ---\n",
      "NULLs removed: 0\n",
      "Duplicates removed: 0\n",
      "Invalid IDs removed: 0\n",
      "\n",
      "--- Validation Report: Item ---\n",
      "NULLs replaced: 333\n",
      "Invalid text replaced: 292\n",
      "Sample invalid text: ['error', 'error', 'error']\n",
      "\n",
      "--- Validation Report: Quantity ---\n",
      "Original nulls: 138\n",
      "Invalid strings: 341\n",
      "Sample invalid text: ['ERROR', 'ERROR', 'UNKNOWN']\n",
      "Final Total Nulls: 479\n",
      "\n",
      "--- Validation Report: Price Per Unit ---\n",
      "Original nulls: 179\n",
      "Invalid strings: 354\n",
      "Sample invalid text: ['ERROR', 'UNKNOWN', 'UNKNOWN']\n",
      "Final Total Nulls: 533\n",
      "\n",
      "--- Validation Report: Total Spent ---\n",
      "Original nulls: 173\n",
      "Invalid strings: 329\n",
      "Sample invalid text: ['ERROR', 'ERROR', 'UNKNOWN']\n",
      "Final Total Nulls: 502\n",
      "\n",
      "--- Validation Report: Payment Method ---\n",
      "NULLs replaced: 2579\n",
      "Invalid text replaced: 306\n",
      "Sample invalid text: ['error', 'error', 'error']\n",
      "\n",
      "--- Validation Report: Location ---\n",
      "NULLs replaced: 3265\n",
      "Invalid text replaced: 358\n",
      "Sample invalid text: ['error', 'error', 'error']\n",
      "\n",
      "--- Validation Report: Transaction Date ---\n",
      "Original nulls: 159\n",
      "Invalid dates: 301\n",
      "Sample invalid dates: ['ERROR', 'ERROR', 'ERROR']\n",
      "Final Total Nulls: 460\n",
      "\n",
      "--- Derived Column Validation (Exact Match): Total Spent ---\n",
      "Invalid rows found: 1456\n",
      "Sample invalid values:\n",
      "     Quantity  Price Per Unit  Total Spent\n",
      "2        4.0             1.0          NaN\n",
      "20       NaN             4.0         20.0\n",
      "25       3.0             4.0          NaN\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates()\n",
    "\n",
    "def validate_ID(df, column):\n",
    "    \"\"\"\n",
    "    Validates and cleans a column of type ID:\n",
    "    - Removes rows with null IDs\n",
    "    - Removes duplicate rows\n",
    "    - Validates the format of the IDs and removes the invalid ones\n",
    "    - Logs the summary of changes made\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The input DataFrame\n",
    "        column (str): The name of the ID column to validate\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Updated DataFrame with cleaned ID values\n",
    "    \"\"\"\n",
    "    \n",
    "    validation_log = {\n",
    "    'column': column,\n",
    "    'nulls_removed': 0,\n",
    "    'duplicates_removed': 0,\n",
    "    'invalid_ids_removed': 0,\n",
    "    'invalid_samples': []\n",
    "    }\n",
    "\n",
    "    # Handle NULLs\n",
    "    null_mask = df[column].isna()\n",
    "    if null_mask.any():\n",
    "        validation_log['nulls_removed'] = null_mask.sum()\n",
    "        df = df[~null_mask].copy()\n",
    "\n",
    "    # Check for duplicates\n",
    "    duplicate_mask = df.duplicated(subset=column, keep=\"first\")\n",
    "    if duplicate_mask.any():\n",
    "        validation_log[\"duplicates_removed\"] = duplicate_mask.sum()\n",
    "        df = df[~duplicate_mask].copy()\n",
    "\n",
    "    # Validate the format of IDs\n",
    "    valid_mask = df[column].str.match(r'^TXN_\\d{7}$', case=False, na=False)\n",
    "    invalid_mask = ~valid_mask\n",
    "    if invalid_mask.any():\n",
    "        validation_log[\"invalid_ids_removed\"] = invalid_mask.sum()\n",
    "        validation_log['invalid_samples'] = df.loc[\n",
    "            invalid_mask, column\n",
    "        ].head(3).tolist()\n",
    "        df = df[valid_mask].copy()\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"\\n--- Validation Report: {column} ---\")\n",
    "    print(f\"NULLs removed: {validation_log['nulls_removed']}\")\n",
    "    print(f\"Duplicates removed: {validation_log['duplicates_removed']}\")\n",
    "    print(f\"Invalid IDs removed: {validation_log['invalid_ids_removed']}\")\n",
    "    if validation_log['invalid_ids_removed'] > 0:\n",
    "        print(f\"Sample invalid IDs: {validation_log['invalid_samples']}\")\n",
    "        print(f\"Expected format: 'TXN_1234567' (case-insensitive).\")\n",
    "\n",
    "    return df\n",
    "                                                                               ##########################\n",
    "def validate_categorical(df, column, values):\n",
    "    \"\"\"\n",
    "    Validates and cleans a categorical column:\n",
    "    - Replaces nulls with 'unknown'\n",
    "    - Replaces invalid text with unknown\n",
    "    - Prints the summary of changes made\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The input DataFrame\n",
    "        column (str): The name of the ID column to validate\n",
    "        values (str list): The names of allowed categorical values\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Updated DataFrame with cleaned categorical values\n",
    "    \"\"\"\n",
    "    \n",
    "    df[column] = df[column].str.lower()\n",
    "\n",
    "    validation_log = {\n",
    "    'column': column,\n",
    "    'nulls_replaced': 0,\n",
    "    'invalid_text_replaced': 0,\n",
    "    'invalid_samples': []\n",
    "    }\n",
    "\n",
    "    # Handle NULLs\n",
    "    null_mask = df[column].isna()\n",
    "    if null_mask.any():\n",
    "        validation_log['nulls_replaced'] = null_mask.sum()\n",
    "        df[column] = df[column].fillna('unknown')\n",
    "\n",
    "    # Handle invalid text\n",
    "    valid_mask = df[column].isin(values)\n",
    "    invalid_mask = ~valid_mask\n",
    "    invalid_rows = invalid_mask.copy()\n",
    "    validation_log['invalid_text_replaced'] = invalid_mask.sum()\n",
    "    validation_log['invalid_samples'] = df.loc[\n",
    "        invalid_mask, column\n",
    "    ].head(3).tolist()\n",
    "    df[column] = df[column].where(~invalid_mask, 'unknown')\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n--- Validation Report: {column} ---\")\n",
    "    print(f\"NULLs replaced: {validation_log['nulls_replaced']}\")\n",
    "    print(f\"Invalid text replaced: {validation_log['invalid_text_replaced']}\")\n",
    "    if validation_log['invalid_text_replaced'] > 0:\n",
    "        print(f\"Sample invalid text: {validation_log['invalid_samples']}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def validate_numeric(df, column):\n",
    "    \"\"\"\n",
    "    Validates and cleans a numeric column:\n",
    "    - Replaces invalid text with null\n",
    "    - Prints the summary of changes made\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The input DataFrame\n",
    "        column (str): The name of the numeric column to validate\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Updated DataFrame with cleaned numeric values\n",
    "    \"\"\"\n",
    "    \n",
    "    validation_log = {\n",
    "    'column': column,\n",
    "    'original_nulls': 0,\n",
    "    'invalid_strings': 0, \n",
    "    'invalid_samples': [],\n",
    "    'final_total_nulls': 0\n",
    "    }\n",
    "\n",
    "    # Handle nulls\n",
    "    original_nulls = df[column].isna()\n",
    "    validation_log['original_nulls'] = original_nulls.sum()\n",
    "    invalid_mask = pd.to_numeric(df[column], errors='coerce').isna()\n",
    "\n",
    "    # Handle invalid values\n",
    "    invalid_string_mask = invalid_mask & ~original_nulls\n",
    "    validation_log['invalid_strings'] = invalid_string_mask.sum()\n",
    "    validation_log['invalid_samples'] = df.loc[\n",
    "        invalid_string_mask, column\n",
    "    ].tolist()[:3]\n",
    "    df[column] = pd.to_numeric(df[column], errors=\"coerce\")\n",
    "    validation_log['final_total_nulls'] = df[column].isna().sum()\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"\\n--- Validation Report: {column} ---\")\n",
    "    print(f\"Original nulls: {validation_log['original_nulls']}\")\n",
    "    print(f\"Invalid strings: {validation_log['invalid_strings']}\")\n",
    "    if validation_log['invalid_strings'] > 0:\n",
    "        print(f\"Sample invalid text: {validation_log['invalid_samples']}\")\n",
    "    print(f\"Final Total Nulls: {validation_log['final_total_nulls']}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def validate_datetime(df, column):\n",
    "\n",
    "    \"\"\"\n",
    "    Validates and cleans a datetime column:\n",
    "    - Replaces invalid dates with null\n",
    "    - Prints the summary of changes made\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The input DataFrame\n",
    "        column (str): The name of the datetime column to validate\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Updated DataFrame with cleaned datetime values\n",
    "    \"\"\"\n",
    "\n",
    "    validation_log = {\n",
    "    'column': column,\n",
    "    'original_nulls': 0,\n",
    "    'invalid_dates': 0, \n",
    "    'invalid_samples': [],\n",
    "    'final_total_nulls': 0\n",
    "    }\n",
    "\n",
    "    # Handle nulls\n",
    "    original_nulls = df[column].isna()\n",
    "    validation_log['original_nulls'] = original_nulls.sum()\n",
    "    invalid_mask = pd.to_datetime(df[column], errors='coerce').isna()\n",
    "\n",
    "    # Handle invalid dates\n",
    "    invalid_mask_no_null = invalid_mask & ~original_nulls\n",
    "    validation_log['invalid_dates'] = invalid_mask_no_null.sum()\n",
    "    validation_log['invalid_samples'] = df.loc[\n",
    "        invalid_mask_no_null, column].tolist()[:3]\n",
    "    df[column] = pd.to_datetime(df[column], errors=\"coerce\")\n",
    "    validation_log['final_total_nulls'] = df[column].isna().sum()\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"\\n--- Validation Report: {column} ---\")\n",
    "    print(f\"Original nulls: {validation_log['original_nulls']}\")\n",
    "    print(f\"Invalid dates: {validation_log['invalid_dates']}\")\n",
    "    if validation_log['invalid_dates'] > 0:\n",
    "        print(f\"Sample invalid dates: {validation_log['invalid_samples']}\")\n",
    "    print(f\"Final Total Nulls: {validation_log['final_total_nulls']}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def validate_derived_column(df, derived_col, input_cols, formula_fn):\n",
    "    \n",
    "    \"\"\"\n",
    "    Validates and replaces the values of a derived column\n",
    "    - Replaces invalid values with the correct values derived\n",
    "    from input columns.\n",
    "    - Prints the summary of changes made\n",
    "\n",
    "    Parameters:\n",
    "        df (DataFrame): The input DataFrame\n",
    "        derived_col (str): The name of the derived column to validate\n",
    "        input_cols (str list): The names of the columns from which the\n",
    "        derived column is calculated\n",
    "        formula_fn: A function that performs the calculation on the\n",
    "        input columns to get the expected derived column and returns\n",
    "        it as a series.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Updated DataFrame with cleaned derived column values\n",
    "    \"\"\"\n",
    "    \n",
    "    expected = formula_fn(df)\n",
    "    invalid_mask = df[derived_col] != expected\n",
    "\n",
    "    validation_log = {\n",
    "        'column': derived_col,\n",
    "        'invalid_rows': invalid_mask.sum(),\n",
    "        'invalid_samples': df[invalid_mask][input_cols + [derived_col]].head(3)\n",
    "    }\n",
    "\n",
    "    df.loc[invalid_mask, derived_col] = expected[invalid_mask]\n",
    "\n",
    "    # Print report\n",
    "    print(f\"\\n--- Derived Column Validation (Exact Match): {derived_col} ---\")\n",
    "    print(f\"Invalid rows found: {validation_log['invalid_rows']}\")\n",
    "    if validation_log['invalid_rows'] > 0:\n",
    "        print(f\"Sample invalid values:\\n {validation_log['invalid_samples']}\")\n",
    "\n",
    "    return df\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "df = validate_ID(df, 'Transaction ID')\n",
    "\n",
    "item_values = [\n",
    "    'juice', 'coffee', 'salad',\n",
    "    'cake', 'sandwich', 'smoothie',\n",
    "    'cookie', 'tea', 'unknown'\n",
    "]\n",
    "df = validate_categorical(df, 'Item', item_values)\n",
    "\n",
    "df = validate_numeric(df, 'Quantity')\n",
    "\n",
    "df = validate_numeric(df, 'Price Per Unit')\n",
    "\n",
    "df = validate_numeric(df, 'Total Spent')\n",
    "\n",
    "payment_values = [\n",
    "    'digital wallet', 'credit card',\n",
    "    'cash', 'unknown'\n",
    "]\n",
    "\n",
    "df = validate_categorical(df, 'Payment Method', payment_values)\n",
    "\n",
    "location_values = [\n",
    "    'takeaway', 'in-store',\n",
    "    'unknown']\n",
    "\n",
    "df = validate_categorical(df, 'Location', location_values)\n",
    "\n",
    "df = validate_datetime(df, 'Transaction Date')\n",
    "\n",
    "def compute_total_spent(df):\n",
    "    return df['Quantity'] * df['Price Per Unit']\n",
    "\n",
    "df = validate_derived_column(\n",
    "    df,\n",
    "    'Total Spent',\n",
    "    ['Quantity', 'Price Per Unit'],\n",
    "    compute_total_spent\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f49f2e3e-2b61-4cb7-bc0a-61cdc4fe1cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_path = f\"output/cleaned_sales_{timestamp}.xlsx\"\n",
    "df.to_excel(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
